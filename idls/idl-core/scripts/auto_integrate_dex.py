#!/usr/bin/env uv run
# /// script
# dependencies = ["toml", "jinja2"]
# ///
"""
ğŸš€ DEXåè®®è‡ªåŠ¨é›†æˆå·¥å…· (UVç‰ˆæœ¬)

åŠŸèƒ½:
- æ™ºèƒ½å»é™¤Cargo.tomlä¸­çš„workspaceå£°æ˜
- è‡ªåŠ¨ç”Ÿæˆsrc/dex/ä¸‹çš„parserå®ç°  
- é‡å¤è¿è¡Œä¿æŠ¤å’Œæ™ºèƒ½åˆ¤æ–­
- ç°ä»£åŒ–çš„UVå·¥å…·é“¾æ”¯æŒ

ç”¨æ³•:
    uv run scripts/auto_integrate_dex.py
    æˆ–
    chmod +x scripts/auto_integrate_dex.py && ./scripts/auto_integrate_dex.py
"""

import os
import re
import sys
from pathlib import Path
from typing import List, Dict, Optional, Tuple
import toml
from jinja2 import Environment, FileSystemLoader

class UVDexIntegrator:
    def __init__(self):
        self.base_dir = Path.cwd()
        self.crates_dir = self.base_dir / "crates"
        self.dex_dir = self.base_dir / "src" / "dex"
        self.scripts_dir = self.base_dir / "scripts"
        self.templates_dir = self.scripts_dir / "templates"
        
        # è®¾ç½®Jinja2ç¯å¢ƒ
        self.jinja_env = Environment(
            loader=FileSystemLoader(self.templates_dir),
            trim_blocks=True,
            lstrip_blocks=True
        )
        
    def run(self) -> bool:
        """ä¸»æ‰§è¡Œå‡½æ•°"""
        print("ğŸš€ UV DEXåè®®è‡ªåŠ¨é›†æˆå·¥å…·å¯åŠ¨")
        print("=" * 50)
        
        if not self.validate_environment():
            return False
            
        # 1. æ‰«ææ¥å£åº“
        interface_libs = self.scan_interface_libraries()
        if not interface_libs:
            print("âŒ æœªå‘ç°ä»»ä½•æ¥å£åº“")
            return False
            
        print(f"ğŸ“¦ å‘ç° {len(interface_libs)} ä¸ªæ¥å£åº“")
        
        # 2. å¤„ç†workspace (æ™ºèƒ½åˆ¤æ–­)
        print("\nğŸ”§ å¤„ç†Cargo.toml workspaceå£°æ˜:")
        workspace_results = self.process_cargo_workspaces(interface_libs)
        
        # 3. ç”ŸæˆDEXè§£æå™¨ (æ™ºèƒ½åˆ¤æ–­)
        print("\nğŸ—ï¸  ç”ŸæˆDEXè§£æå™¨:")
        parser_results = self.generate_dex_parsers(interface_libs)
        
        # 4. è¾“å‡ºæ‘˜è¦
        self.print_summary(workspace_results, parser_results)
        return True
    
    def validate_environment(self) -> bool:
        """éªŒè¯è¿è¡Œç¯å¢ƒ"""
        if not self.crates_dir.exists():
            print("âŒ cratesç›®å½•ä¸å­˜åœ¨ï¼Œè¯·ç¡®ä¿åœ¨idl-coreæ ¹ç›®å½•è¿è¡Œ")
            return False
            
        if not self.dex_dir.exists():
            print(f"ğŸ“ åˆ›å»ºdexç›®å½•: {self.dex_dir}")
            self.dex_dir.mkdir(parents=True)
            
        if not self.templates_dir.exists():
            print(f"ğŸ“ åˆ›å»ºtemplatesç›®å½•: {self.templates_dir}")
            self.templates_dir.mkdir(parents=True)
            
        return True
    
    def scan_interface_libraries(self) -> List[Dict]:
        """æ‰«æå¹¶åˆ†ææ‰€æœ‰æ¥å£åº“"""
        libs = []
        
        for crate_path in self.crates_dir.glob("sol_*_interface"):
            if crate_path.is_dir():
                lib_info = self.analyze_interface_library(crate_path)
                if lib_info:
                    libs.append(lib_info)
                    
        return sorted(libs, key=lambda x: x['name'])
    
    def analyze_interface_library(self, crate_path: Path) -> Optional[Dict]:
        """åˆ†æå•ä¸ªæ¥å£åº“çš„ä¿¡æ¯"""
        try:
            # æŸ¥æ‰¾å®é™…çš„Cargo.toml (å¤„ç†åµŒå¥—ç›®å½•ç»“æ„)
            cargo_toml_path = self.find_cargo_toml(crate_path)
            if not cargo_toml_path:
                return None
            
            # è¯»å–Cargo.tomlè·å–åŒ…ä¿¡æ¯
            cargo_data = toml.load(cargo_toml_path)
            package_name = cargo_data.get('package', {}).get('name', crate_path.name)
            
            # æå–åè®®ä¿¡æ¯
            protocol_info = self.extract_protocol_info(package_name)
            
            lib_info = {
                'name': package_name,
                'crate_name': package_name.replace('-', '_'),
                'crate_path': crate_path,
                'cargo_toml_path': cargo_toml_path,
                **protocol_info
            }
            
            return lib_info
            
        except Exception as e:
            print(f"âŒ {crate_path.name}: åˆ†æå¤±è´¥ - {e}")
            return None
    
    def find_cargo_toml(self, crate_path: Path) -> Optional[Path]:
        """æ™ºèƒ½æŸ¥æ‰¾Cargo.tomlæ–‡ä»¶"""
        # ç›´æ¥æŸ¥æ‰¾
        direct_cargo = crate_path / "Cargo.toml"
        if direct_cargo.exists():
            return direct_cargo
            
        # æŸ¥æ‰¾å­ç›®å½•ä¸­çš„Cargo.toml (å¤„ç†åµŒå¥—ç»“æ„)
        for sub_dir in crate_path.iterdir():
            if sub_dir.is_dir():
                cargo_toml = sub_dir / "Cargo.toml"
                if cargo_toml.exists():
                    return cargo_toml
                    
        return None
    
    def extract_protocol_info(self, package_name: str) -> Dict:
        """ä»åŒ…åæå–åè®®ä¿¡æ¯"""
        # åè®®æ˜ å°„è¡¨
        protocol_mapping = {
            'sol_raydium_interface': {
                'dex_name': 'raydium',
                'display_name': 'Raydium',
                'instruction_type': 'ProgramInstruction',
                'account_type': 'RaydiumAccount',
            },
            'sol_raydium_launchpad_interface': {
                'dex_name': 'raydium_launchpad',
                'display_name': 'RaydiumLaunchpad',
                'instruction_type': 'RaydiumLaunchpadInstruction',
                'account_type': 'RaydiumLaunchpadAccount',
            },
            'sol_pump_fun_interface': {
                'dex_name': 'pump_fun',
                'display_name': 'PumpFun',
                'instruction_type': 'PumpfunInstruction',
                'account_type': 'PumpfunAccount',
            },
            'sol_orca_whirlpool_interface': {
                'dex_name': 'orca_whirlpool',
                'display_name': 'OrcaWhirlpool',
                'instruction_type': 'WhirlpoolInstruction',
                'account_type': 'WhirlpoolAccount',
            },
            'sol_meteora_dbc_interface': {
                'dex_name': 'meteora_dbc',
                'display_name': 'MeteoraDbc',
                'instruction_type': 'MeteoraDbcInstruction',
                'account_type': 'MeteoraDbcAccount',
            },
            'sol_pump_amm_interface': {
                'dex_name': 'pump_amm',
                'display_name': 'PumpAmm',
                'instruction_type': 'PumpAmmInstruction',
                'account_type': 'PumpAmmAccount',
            },
            'sol_phoenix_interface': {
                'dex_name': 'phoenix',
                'display_name': 'Phoenix',
                'instruction_type': 'PhoenixInstruction',
                'account_type': 'PhoenixAccount',
            },
            'sol_serum_interface': {
                'dex_name': 'serum',
                'display_name': 'Serum',
                'instruction_type': 'SerumInstruction',
                'account_type': 'SerumAccount',
            },
        }
        
        # è¿”å›æ˜ å°„ä¿¡æ¯æˆ–é»˜è®¤å€¼
        return protocol_mapping.get(package_name, {
            'dex_name': package_name.replace('sol_', '').replace('_interface', ''),
            'display_name': package_name.replace('sol_', '').replace('_interface', '').title(),
            'instruction_type': 'ProgramInstruction',
            'account_type': 'ProgramAccount',
        })
    
    def is_workspace_already_removed(self, cargo_toml_path: Path) -> bool:
        """æ£€æŸ¥workspaceæ˜¯å¦å·²ç»è¢«åˆ é™¤"""
        try:
            content = cargo_toml_path.read_text()
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ç‹¬ç«‹çš„[workspace]è¡Œ
            return not re.search(r'^\[workspace\]\s*$', content, re.MULTILINE)
        except Exception:
            return False
    
    def is_parser_already_generated(self, dex_name: str) -> bool:
        """æ£€æŸ¥DEXè§£æå™¨æ˜¯å¦å·²ç»ç”Ÿæˆ"""
        parser_dir = self.dex_dir / dex_name / "parser"
        protocol_mod = self.dex_dir / dex_name / "mod.rs"
        
        required_files = [
            parser_dir / "instructions.rs",
            parser_dir / "accounts.rs",
            parser_dir / "mod.rs",
            protocol_mod,
        ]
        
        # æ£€æŸ¥æ‰€æœ‰å¿…éœ€æ–‡ä»¶å­˜åœ¨ä¸”æœ‰å†…å®¹
        return all(
            f.exists() and f.stat().st_size > 50 
            for f in required_files
        )
    
    def remove_workspace_declaration(self, cargo_toml_path: Path):
        """åˆ é™¤Cargo.tomlä¸­çš„workspaceå£°æ˜"""
        content = cargo_toml_path.read_text()
        
        # åˆ é™¤ç‹¬ç«‹çš„[workspace]è¡Œ
        updated_content = re.sub(r'^\[workspace\]\s*\n', '', content, flags=re.MULTILINE)
        
        # åªæœ‰å†…å®¹å‘ç”Ÿå˜åŒ–æ—¶æ‰å†™å…¥
        if updated_content != content:
            cargo_toml_path.write_text(updated_content)
    
    def create_parser_implementation(self, lib_info: Dict):
        """åˆ›å»ºå®Œæ•´çš„parserå®ç°"""
        dex_name = lib_info['dex_name']
        parser_dir = self.dex_dir / dex_name / "parser"
        protocol_dir = self.dex_dir / dex_name
        
        # åˆ›å»ºç›®å½•
        parser_dir.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆinstructions.rs
        instructions_content = self.render_template('instruction_parser.rs.jinja2', lib_info)
        (parser_dir / "instructions.rs").write_text(instructions_content)
        
        # ç”Ÿæˆaccounts.rs
        accounts_content = self.render_template('account_parser.rs.jinja2', lib_info)
        (parser_dir / "accounts.rs").write_text(accounts_content)
        
        # ç”Ÿæˆparser/mod.rs
        parser_mod_content = self.render_template('parser_mod.rs.jinja2', lib_info)
        (parser_dir / "mod.rs").write_text(parser_mod_content)
        
        # ç”Ÿæˆprotocol/mod.rs
        protocol_mod_content = self.render_template('protocol_mod.rs.jinja2', lib_info)
        (protocol_dir / "mod.rs").write_text(protocol_mod_content)
    
    def render_template(self, template_name: str, variables: Dict) -> str:
        """æ¸²æŸ“Jinja2æ¨¡æ¿"""
        template = self.jinja_env.get_template(template_name)
        return template.render(**variables)
    
    def process_cargo_workspaces(self, libs: List[Dict]) -> Dict:
        """æ™ºèƒ½å¤„ç†Cargo.toml workspaceå£°æ˜"""
        results = {"processed": 0, "skipped": 0, "failed": 0}
        
        for lib in libs:
            cargo_toml_path = lib['cargo_toml_path']
            
            # æ™ºèƒ½åˆ¤æ–­æ˜¯å¦å·²å¤„ç†
            if self.is_workspace_already_removed(cargo_toml_path):
                print(f"   â­ï¸  {lib['name']}: workspaceå·²åˆ é™¤")
                results["skipped"] += 1
                continue
            
            # åˆ é™¤workspaceå£°æ˜
            try:
                self.remove_workspace_declaration(cargo_toml_path)
                print(f"   âœ… {lib['name']}: åˆ é™¤workspaceå£°æ˜")
                results["processed"] += 1
            except Exception as e:
                print(f"   âŒ {lib['name']}: åˆ é™¤å¤±è´¥ - {e}")
                results["failed"] += 1
                
        return results
    
    def generate_dex_parsers(self, libs: List[Dict]) -> Dict:
        """æ™ºèƒ½ç”ŸæˆDEXè§£æå™¨"""
        results = {"generated": 0, "skipped": 0, "failed": 0}
        
        for lib in libs:
            dex_name = lib['dex_name']
            
            # æ™ºèƒ½åˆ¤æ–­æ˜¯å¦å·²ç”Ÿæˆ
            if self.is_parser_already_generated(dex_name):
                print(f"   â­ï¸  {lib['name']}: parserå·²å­˜åœ¨")
                results["skipped"] += 1
                continue
            
            # ç”Ÿæˆparserå®ç°
            try:
                self.create_parser_implementation(lib)
                print(f"   âœ… {lib['name']}: ç”Ÿæˆparserå®Œæˆ")
                results["generated"] += 1
            except Exception as e:
                print(f"   âŒ {lib['name']}: ç”Ÿæˆå¤±è´¥ - {e}")
                results["failed"] += 1
                
        return results
    
    def print_summary(self, workspace_results: Dict, parser_results: Dict):
        """æ‰“å°æ‰§è¡Œæ‘˜è¦"""
        print("\nğŸ“Š æ‰§è¡Œæ‘˜è¦:")
        print(f"   Workspaceå¤„ç†: {workspace_results['processed']}ä¸ªå¤„ç†, {workspace_results['skipped']}ä¸ªè·³è¿‡, {workspace_results['failed']}ä¸ªå¤±è´¥")
        print(f"   Parserç”Ÿæˆ: {parser_results['generated']}ä¸ªç”Ÿæˆ, {parser_results['skipped']}ä¸ªè·³è¿‡, {parser_results['failed']}ä¸ªå¤±è´¥")
        
        if workspace_results['failed'] == 0 and parser_results['failed'] == 0:
            print("\nâœ… æ‰€æœ‰æ“ä½œæˆåŠŸå®Œæˆ!")
        else:
            print("\nâš ï¸  éƒ¨åˆ†æ“ä½œæœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°æ—¥å¿—")

def main():
    """ä¸»å‡½æ•°"""
    try:
        integrator = UVDexIntegrator()
        success = integrator.run()
        
        if success:
            print("\nğŸ‰ DEXåè®®é›†æˆå·¥å…·æ‰§è¡Œå®Œæˆ!")
            sys.exit(0)
        else:
            print("\nâŒ æ‰§è¡Œå¤±è´¥!")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­")
        sys.exit(130)
    except Exception as e:
        print(f"\nâŒ æ„å¤–é”™è¯¯: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()